{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "def show_results(ori, pred):\n",
    "    x_ax = range(len(ori))\n",
    "    plt.plot(x_ax, ori, linewidth=1.2, label=\"original\")\n",
    "    plt.plot(x_ax, pred, linewidth=1, label=\"predicted\")\n",
    "    plt.title(\"y-true and y-predicted data\")\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.legend(loc='best', fancybox=True, shadow=True)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def show_confusion_matrix(ori, pred):\n",
    "    ConfusionMatrixDisplay.from_predictions(ori, pred)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plusieurs algorithmes sont testés, afin de faciliter les tests, vous pouvez spécifier lequel utiliser ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_DECISION_TREE = False\n",
    "DO_GRADIENT_BOOSTING = True\n",
    "DO_ADABOOST_WITH_DT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing import getData\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = getData()\n",
    "\n",
    "x_train = x_train.squeeze()\n",
    "x_test = x_test.squeeze()\n",
    "x_test = x_test.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version brut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "# decision tree\n",
    "if DO_DECISION_TREE:\n",
    "    print('decision tree classifier')\n",
    "    dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "    dt.fit(x_train, y_train)\n",
    "    score = dt.score(x_train, y_train)\n",
    "    print('score:', score)\n",
    "\n",
    "    pred = dt.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print('accuracy:', accuracy)\n",
    "\n",
    "    show_results(y_test, pred)\n",
    "    show_confusion_matrix(y_test, pred) # dunno why the confusion matrix appears twice\n",
    "    \n",
    "\n",
    "# GradientBoostingClassifier\n",
    "if DO_GRADIENT_BOOSTING:\n",
    "    print('gradient boosting classifier')\n",
    "    gs = GradientBoostingClassifier()\n",
    "    gs.fit(x_train, y_train)\n",
    "    score = gs.score(x_train, y_train)\n",
    "    print('score:', score)\n",
    "\n",
    "    pred = gs.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print('accuracy:', accuracy)\n",
    "\n",
    "    show_results(y_test, pred)\n",
    "    show_confusion_matrix(y_test, pred) # dunno why the confusion matrix appears twice\n",
    "\n",
    "# Adaboost + dt\n",
    "if DO_ADABOOST_WITH_DT:\n",
    "    print('Adaboost with decision tree')\n",
    "    ada_dt = AdaBoostClassifier(tree.DecisionTreeClassifier())\n",
    "    ada_dt.fit(x_train, y_train)\n",
    "    score = ada_dt.score(x_train, y_train)\n",
    "    print('score:', score)\n",
    "\n",
    "    pred = ada_dt.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print('accuracy:', accuracy)\n",
    "\n",
    "    show_results(y_test, pred)\n",
    "    show_confusion_matrix(y_test, pred) # dunno why the confusion matrix appears twice\n",
    "\n",
    "# not working\n",
    "# # Adaboost + gb\n",
    "# if DO_ADABOOST_WITH_GB:\n",
    "#     print('Adaboost with gradient boosting')\n",
    "#     ada_gb = AdaBoostClassifier(GradientBoostingClassifier())\n",
    "#     ada_gb.fit(x_train, y_train)\n",
    "#     score = ada_gb.score(x_train, y_train)\n",
    "#     print('score:', score)\n",
    "\n",
    "#     pred = ada_gb.predict(x_test)\n",
    "#     accuracy = accuracy_score(y_test, pred)\n",
    "#     print('accuracy:', accuracy)\n",
    "\n",
    "#     show_results(y_test, pred)\n",
    "#     show_confusion_matrix(y_test, pred) # dunno why the confusion matrix appears twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maintenant essayons avec un grid search\n",
    "\n",
    "commençons par installer une pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# decision tree classifier\n",
    "if DO_DECISION_TREE:\n",
    "    dt_pipe = Pipeline(steps=[\n",
    "                        ('dec_tree', tree.DecisionTreeClassifier()),\n",
    "                    ])\n",
    "\n",
    "    dt_params = dict(\n",
    "                dec_tree__criterion = ['gini', 'entropy'],\n",
    "                dec_tree__max_depth = [i for i in range (1, 20)]\n",
    "                )\n",
    "\n",
    "# gradient boosting classifier\n",
    "if DO_GRADIENT_BOOSTING:\n",
    "    gb_pipe = Pipeline(steps=[\n",
    "                        ('gra_boost', GradientBoostingClassifier()),\n",
    "                    ])\n",
    "\n",
    "    gb_params = dict(\n",
    "                gra_boost__criterion = ['friedman_mse', 'squared_error'],\n",
    "                gra_boost__max_depth = [i for i in range (1, 3)] # it takes a long time to test with higher values\n",
    "                )\n",
    "    # n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0\n",
    "\n",
    "# if DO_ADABOOST_WITH_GS_DT:\n",
    "#     ada_dt_pipe = Pipeline(steps=[\n",
    "#                         ('ada_dt', AdaBoostClassifier()),\n",
    "#                     ])\n",
    "\n",
    "#     ada_dt_params = dict(\n",
    "#                 ada_dt__base_estimator = [tree.DecisionTreeClassifier()],\n",
    "#                 ada_dt__algorithm = ['SAMME', 'SAMME.R'],\n",
    "#                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant faisons les grid search\n",
    "\n",
    "Si vous ne voulez pas les faire, vous pouvez sauter cette étape et lancer le shortcut à la place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree grid search\n",
    "if DO_DECISION_TREE:\n",
    "    gs_dt = GridSearchCV(dt_pipe, dt_params)\n",
    "    gs_dt.fit(x_train, y_train)\n",
    "\n",
    "    # pca__n_components = gsc.best_estimator_.get_params()['pca__n_components']\n",
    "    dec_tree__criterion = gs_dt.best_estimator_.get_params()['dec_tree__criterion']\n",
    "    dec_tree__max_depth = gs_dt.best_estimator_.get_params()['dec_tree__max_depth']\n",
    "\n",
    "    print('decision tree classifier')\n",
    "    print('Best Criterion:', dec_tree__criterion)\n",
    "    print('Best max_depth:', dec_tree__max_depth)\n",
    "\n",
    "\n",
    "# gradient boosting grid search\n",
    "if DO_GRADIENT_BOOSTING:\n",
    "    gs_gb = GridSearchCV(gb_pipe, gb_params)\n",
    "    gs_gb.fit(x_train, y_train)\n",
    "\n",
    "    gra_boost__criterion = gs_gb.best_estimator_.get_params()['gra_boost__criterion']\n",
    "    gra_boost__max_depth = gs_gb.best_estimator_.get_params()['gra_boost__max_depth']\n",
    "\n",
    "\n",
    "    print('gradient boosting classifier')\n",
    "    print('Best Criterion:', gra_boost__criterion)\n",
    "    print('Best max_depth:', gra_boost__max_depth)\n",
    "\n",
    "\n",
    "# decision tree grid search\n",
    "if DO_ADABOOST_WITH_DT:\n",
    "    gs_ada_dt = GridSearchCV(ada_dt_pipe, ada_dt_params)\n",
    "    gs_ada_dt.fit(x_train, y_train)\n",
    "\n",
    "    ada_dt__algorithm = gs_ada_dt.best_estimator_.get_params()['ada_dt__algorithm']\n",
    "\n",
    "    print('Ada boost + decision tree classifier')\n",
    "    print('Best Algorithm:', ada_dt__algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shortcut (dé-commenter pour l'utiliser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the gs_dt is not a gridsearch, only a decision tree classifier\n",
    "# # the name is used to keep a consistent naming for later code, when taking this shortcut\n",
    "# if DO_DECISION_TREE:\n",
    "#     dec_tree__criterion = 'gini'\n",
    "#     dec_tree__max_depth = 3\n",
    "#     gs_dt = tree.DecisionTreeClassifier(criterion=dec_tree__criterion, max_depth=dec_tree__max_depth)\n",
    "\n",
    "# # the gs_gb is not a gridsearch, only a gradient boosting classifier\n",
    "# # the name is used to keep a consistent naming for later code, when taking this shortcut\n",
    "# if DO_GRADIENT_BOOSTING:\n",
    "#     gra_boost__criterion = 'friedman_mse'\n",
    "#     gra_boost__max_depth = 1\n",
    "\n",
    "#     gs_gb = GradientBoostingClassifier(criterion=gra_boost__criterion, max_depth=gra_boost__max_depth)\n",
    "#     gs_gb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_DECISION_TREE:\n",
    "    print('decision tree classifier')\n",
    "    print('score:', gs_dt.score(x_train, y_train))\n",
    "    y_pred = gs_dt.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print('accuracy:', accuracy)\n",
    "    print('dunno why it is scaled even if we removed it in the pipeline')\n",
    "    show_results(y_test, y_pred)\n",
    "    show_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "if DO_GRADIENT_BOOSTING:\n",
    "    print('gradient boosting classifier')\n",
    "    print('score:', gs_gb.score(x_train, y_train))\n",
    "    y_pred = gs_gb.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print('accuracy::', accuracy)\n",
    "    show_results(y_test, y_pred)\n",
    "    show_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "if DO_ADABOOST_WITH_DT:\n",
    "    print('Ada boost + decision tree classifier')\n",
    "    print('score:', gs_ada_dt.score(x_train, y_train))\n",
    "    y_pred = gs_ada_dt.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print('accuracy:', accuracy)\n",
    "    show_results(y_test, y_pred)\n",
    "    show_confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
